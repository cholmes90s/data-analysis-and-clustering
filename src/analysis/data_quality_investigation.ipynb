{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import pandas as pd\n",
    "import pandas.arrays as pdarray\n",
    "from src.cleaning import integrity_checks\n",
    "import src.cleaning.schema_anon_data as anon_data_schema\n",
    "import numpy as np\n",
    "import src.cleaning as clean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('../../data/anon_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can columns be converted to appropriate data types?\n",
    "file_schema = {\n",
    "  'CustomerId': int,\n",
    "  'SalesOrderNumber': int,\n",
    "  'SalesOrderLineNumber': int,\n",
    "  'Qty': int,\n",
    "  'Brand': 'string',\n",
    "  'ProductType': 'string',\n",
    "  'ProductSupplierID': int,\n",
    "  'Revenue': float,\n",
    "  'Profit': float,\n",
    "  'Freight cost': float,\n",
    "  'SalesTeamName': 'string',\n",
    "}\n",
    "failing_columns = list()\n",
    "for column_name, column_type in file_schema.items():\n",
    "    try:\n",
    "        if column_type in [int, float]:\n",
    "            pd.to_numeric(sales_data[column_name])\n",
    "        sales_data[column_name].astype(column_type)\n",
    "    except Exception as e:\n",
    "        failing_columns.append(column_name)\n",
    "for i in failing_columns:\n",
    "    print(i)\n",
    "\n",
    "# SalesOrderNumber is due to preceeding O instead of 0\n",
    "# Qty is because of commas in numbers e.g. 1,000\n",
    "# ProductSupplierId is because of Null values\n",
    "\n",
    "# Data requires cleaningand formatting before proceeding on further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.isna().sum()\n",
    "# Nulls in:\n",
    "# Brand: Problem as don't know the item being sold\n",
    "# Product Type: Problem as don't know the item being sold\n",
    "# Product Supplier Id: Not a problem is some stuff is refurbished or refunded and then resold?\n",
    "                        # Question to ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are null brands the same rows as null product type?\n",
    "brand_nulls = sales_data.loc[sales_data['Brand'].isna(), :].index\n",
    "product_type_nulls = sales_data.loc[sales_data['ProductType'].isna(), :].index\n",
    "(brand_nulls == product_type_nulls).all()\n",
    "# Yes so removing one will also solve the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type enforced data\n",
    "data_schema = anon_data_schema.schema\n",
    "typed_data = data_schema.enforce_schema(dataframe=sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness before and after\n",
    "sales_data.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed_data.nunique()\n",
    "# Qty uniqueness has decreased as numbers that contained commas are now actual numbers so more likely to exist already, e.g. 1000\n",
    "# SalesOrderNumber uniqueness decreased as some floats are read in as strings and some as number, example give below. So when standardised, uniqueness decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "typed_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each sales order number should be a sale to only one customer, sales order number should not cover multiple customers\n",
    "integrity_checks.mapping_check(typed_data, groupby_column='sales_order_number', check_column='customer_id', number_unique_values=1)\n",
    "# Results agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should each customer only belong to one sales team?\n",
    "integrity_checks.mapping_check(typed_data, groupby_column='customer_id', check_column='sales_team_name', number_unique_values=1)\n",
    "# Results seem to suggest no\n",
    "# Something to investigate if some have multiple sales teams like Corporate and SMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all items in an order shipped on the same date?\n",
    "integrity_checks.mapping_check(typed_data, groupby_column='sales_order_number', check_column='ship_date', number_unique_values=1)\n",
    "# Apparently not, something to investigate, can we save money by shipping all together rather than separate?\n",
    "# Questions: Are the origin points the same, do they have the same product supplier? Do they come straight from product supplier or our warehouse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Can the same SalesOrderLineNumber appear twice on a sales order?\n",
    "integrity_checks.mapping_check(typed_data, groupby_column=['sales_order_number', 'sales_order_line_number'], check_column='ship_date', number_unique_values=1)\n",
    "# Some have same item on same line shipped on different days, suggests that some of the items are not available so have to be shipped later\n",
    "# Althoug for 496125, all come from same supplier, third one has later date, lower revenue, but higher profit, how???? Different webcam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any 0 quantity?\n",
    "typed_data.loc[typed_data['quantity'] == 0, :]\n",
    "# No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any quantity < 0?\n",
    "typed_data.loc[typed_data['quantity'] < 0, :]\n",
    "# Yes, returns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is revenue always positive when quantity is positive?\n",
    "typed_data.loc[((typed_data['quantity'] >  0) & (typed_data['revenue'] < 0)), :]\n",
    "# 2 Rows, likely a mistake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is profit always positive when revenue is positive?\n",
    "typed_data.loc[((typed_data['revenue'] >  0) & (typed_data['profit'] < 0)), :]\n",
    "# No, 9606 rows, possibly because of cost of shipping? Or promotional offers? or advertising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is shipping cost ever negative?\n",
    "typed_data.loc[typed_data['freight_cost'] < 0, :]\n",
    "# Yes? Why?\n",
    "# Can we ship stuff and the product supplier pay us to ship it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "within_order_shipping_dates = typed_data.groupby('sales_order_number')['ship_date'].unique()\n",
    "def days_between(datetimes: pdarray.DatetimeArray):\n",
    "    days_between = list()\n",
    "    if len(datetimes) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        time_order = datetimes.argsort()\n",
    "        for i in range(len(time_order)-1):\n",
    "            days_between.append((datetimes[time_order[i+1]]-datetimes[time_order[i]]).days)\n",
    "        return np.mean(days_between)\n",
    "    \n",
    "days_between_shipments = within_order_shipping_dates.apply(days_between).sort_values(ascending=False)\n",
    "days_between_shipments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do the nulls come from?\n",
    "sales_team_grouped = typed_data.groupby('sales_team_name').count()\n",
    "brand_nulls = typed_data[typed_data['brand'].isna()].groupby('sales_team_name').count()\n",
    "supplier_nulls = typed_data[typed_data['product_supplier_id'].isna()].groupby('sales_team_name').count()\n",
    "supplier_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When did the brand nulls occur?\n",
    "brand_nulls = typed_data[typed_data['brand'].isna()]\n",
    "print(brand_nulls['ship_date'].min())\n",
    "print(brand_nulls['ship_date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = clean.clean_data(sales_data)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers by sales_team in profit\n",
    "# Data is not normally distributed so using quartiles and IQR\n",
    "grouped_data = typed_data.groupby('sales_team_name')['profit']\n",
    "medians = grouped_data.median()\n",
    "lower_quartile = grouped_data.quantile(0.25)\n",
    "upper_quartile = grouped_data.quantile(0.75)\n",
    "iqr = upper_quartile - lower_quartile\n",
    "upper_outlier = upper_quartile + 1.5*iqr\n",
    "lower_outlier = lower_quartile - 1.5*iqr\n",
    "top_percentile = grouped_data.quantile(0.88)\n",
    "lower_percentile = grouped_data.quantile(0.02)\n",
    "top_percentile - upper_outlier\n",
    "lower_percentile - lower_outlier\n",
    "# Removing outliers on this rule would result in removing approximately 15% of the data = 73306 data points which is unacceptable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(typed_data['quantity'], typed_data['profit'])\n",
    "# Looking at the plot, some data could be removed as outliers e.g. profit over 150,000 and quanitity over 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 would be removed for profit \n",
    "typed_data.loc[typed_data['profit']>150_000, :]\n",
    "# 2 would be removed by quantity > 0 and profit > revenue\n",
    "# One more to be removed die to outlier with huge profit not comparable to revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two would be removed for quantity \n",
    "typed_data.loc[typed_data['quantity']>8_000, :]\n",
    "# Keep these are data makes sense, would have to be sold at severe discount though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(typed_data['quantity'], typed_data['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed_data.loc[typed_data['revenue']>900_000, :]\n",
    "# Keep as price makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_count = typed_data.groupby('customer_id').count()\n",
    "grouped_count.loc[grouped_count.ship_date > 5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questionable data, returns of 140 all on the same day, have they been processed in batches of 140? If so, whey different revenue, previously bought at different prices, different models of security camera?\n",
    "# Maybe client was trying out all camera models and choosing one. No good reason to remove, something to raise\n",
    "cleaned_data.loc[cleaned_data['customer_id']==100007165, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed_data.loc[typed_data['customer_id']==100007165, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.loc[sales_data['CustomerId']==100007165, :]\n",
    "# argument to remove as there is sales data going back to 2021, and these are not listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
